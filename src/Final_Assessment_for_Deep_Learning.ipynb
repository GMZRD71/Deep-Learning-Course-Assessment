{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "Assessment Implemented by: Herb Guzman\n",
    "November 2019\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The task consisted of building a Convolutional Neural Network, CNN with Keras 2.2 (TensorFlow) for classifying fashion images.\n",
    "The images are from the MNIST fashion dataset.  This dataset consists of 10 labels of grayscale images of various types of clothing items.\n",
    "The dataset includes 60,000 training images and 10,000 test images, all of these are 28x28 pixels in size.\n",
    "\n",
    "The 10 labels are as follows:\n",
    "    \n",
    "    Label   Description\n",
    "    \n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Task # 1 - Download the dataset using Keras\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task # 2 - Visualize the data\n",
    "# Load relevant library for handling image viewing\n",
    "# View any one of the images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the training dataset\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the test dataset\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d26770898>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the first image (low-res, 28x28)\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the first image in the training set to a temporary variable\n",
    "# for visualization\n",
    "train_img1=x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the single image\n",
    "train_img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the peak color scale value for this image\n",
    "train_img1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d53f4b7f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the image with a grayscale colormap\n",
    "plt.imshow(train_img1,cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task #3 Training Data pre-processing: normalization, reshape and conversion to one-hot encoding\n",
    "# Normalize\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the re-shaped dataset to the array x_train\n",
    "# The reshaped array has one more dimension\n",
    "# This will allow using one-hot encoding\n",
    "x_train = x_train.reshape(60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the new array\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the re-shape for the test dataset\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the new array\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the labels of the training dataset (the y-data) to make sure the\n",
    "# one-hot encoding worked\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to one-hot encoded\n",
    "# First import the Keras Utitiles library and assign it to the \n",
    "# the variable: \"to_categorical\"\n",
    "# This will be used for the one-hot encoding conversion\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As mentioned at the beginning, there are 10 labels/categories\n",
    "# One-hot encoding conversion here:\n",
    "y_cat_train = to_categorical(y_train,10)\n",
    "y_cat_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the training dataset structure\n",
    "y_cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the test dataset structure\n",
    "y_cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, check that the y-test data labels are also\n",
    "# in one-hot encoding order\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task #5\n",
    "# MODEL DEVELOPMENT\n",
    "# Import the pertinent keras libraries needed to build a neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUCT THE MODEL\n",
    "Herbs_DL_AssessmentModel = Sequential()\n",
    "\n",
    "# EXPERIMENT WITH 2 CONVOLUTION LAYERS\n",
    "# 32 Filters, 4x4 kernel size, inputs: 28x28, grayscale, Rectified Linear Unit (ReLU) activation function\n",
    "Herbs_DL_AssessmentModel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "Herbs_DL_AssessmentModel.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# FLATTEN:\n",
    "Herbs_DL_AssessmentModel.add(Flatten())\n",
    "                     \n",
    "# DENSE LAYER\n",
    "# Use 128 neurons\n",
    "Herbs_DL_AssessmentModel.add(Dense(128,activation='relu'))\n",
    "                     \n",
    "# LAST LAYER - DENSE - CLASSIFIER\n",
    "# Use softmax activation function for the output layer\n",
    "Herbs_DL_AssessmentModel.add(Dense(10,activation='softmax'))\n",
    "                     \n",
    "# Compile the model with the following parameters:\n",
    "# loss-function: categorical-crossentropy\n",
    "# optimizer: rmsprop\n",
    "# metrics: accuracy \n",
    "Herbs_DL_AssessmentModel.compile(loss='categorical_crossentropy',\n",
    "                         optimizer='rmsprop',\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the model structure\n",
    "Herbs_DL_AssessmentModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Re-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.3997 - acc: 0.8577\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.2768 - acc: 0.9008\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.2395 - acc: 0.9141\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.2146 - acc: 0.9219\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 29s 480us/step - loss: 0.1969 - acc: 0.9295\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.1838 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 28s 469us/step - loss: 0.1730 - acc: 0.9385\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.1653 - acc: 0.9422\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 28s 473us/step - loss: 0.1565 - acc: 0.9455\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.1506 - acc: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d1bb01048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task #6 TRAINING\n",
    "# Train Herb's Model, use 10 epochs for this example\n",
    "# use the x_train_set to train (fit) the model\n",
    "Herbs_DL_AssessmentModel.fit(x_train,y_cat_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task #7 - TESTING\n",
    "# Now the the model is trained, check the metrics names\n",
    "# Also save the weights\n",
    "# Do all this before testing\n",
    "Herbs_DL_AssessmentModel.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights and other parameters\n",
    "Herbs_DL_AssessmentModel.save('Herbs_DL_AssessmentModel_10Epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 186us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37934122207164767, 0.8977]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model with the weights determined during training\n",
    "Herbs_DL_AssessmentModel.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification metrics libraries from Scikit Learn (sklearn)\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predictions will NOT be One-Hot Encoded\n",
    "# So, we will need to use the original y_test data (not econded)\n",
    "# for the actual prediction/testing\n",
    "Herbs_Model_predictions = Herbs_DL_AssessmentModel.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall that the answer to predictions is already known\n",
    "# in the original y_test dataset\n",
    "y_cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85      1000\n",
      "          1       1.00      0.97      0.98      1000\n",
      "          2       0.75      0.90      0.82      1000\n",
      "          3       0.90      0.92      0.91      1000\n",
      "          4       0.90      0.73      0.81      1000\n",
      "          5       0.97      0.97      0.97      1000\n",
      "          6       0.75      0.73      0.74      1000\n",
      "          7       0.94      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.97      0.95      0.96      1000\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lastly, print the results of the testing\n",
    "# Note that the f1-score averages in the 90's\n",
    "# as do the precision and recall\n",
    "# Using precision, recall and f1-scode is a common\n",
    "# method of evaluation and was the method used in the course\n",
    "print(classification_report(y_test,Herbs_Model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
